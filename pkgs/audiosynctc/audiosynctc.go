package audiosynctc

import (
	"context"
	"crypto/tls"
	"encoding/base64"
	"encoding/json"
	"fmt"
	"net/http"
	"os"
	"path/filepath"
	"strings"

	"github.com/google/uuid"
	openai "github.com/sashabaranov/go-openai"
	"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/common"
	"github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/common/profile"
	tts "github.com/tencentcloud/tencentcloud-sdk-go/tencentcloud/tts/v20190823"
)

// æ•°æ®ç»“æž„
type ScriptData struct {
	Script     []Scene           `json:"script"`
	Characters map[string]string `json:"characters"`
}

type Scene struct {
	SceneID          int            `json:"scene_id"`
	Location         string         `json:"location"`
	TimeOfDay        string         `json:"time_of_day"`
	Characters       []string       `json:"characters"`
	SceneDescription string         `json:"scene_description"`
	Dialogue         []DialogueLine `json:"dialogue"`
	NarrationVO      string         `json:"narration_vo"`
}

type DialogueLine struct {
	Character string `json:"character"`
	Line      string `json:"line"`
	Emotion   string `json:"emotion,omitempty"`
}

// éŸ³è‰²ä¿¡æ¯
type VoiceInfo struct {
	VoiceType string   `json:"voice_type"`
	VoiceName string   `json:"voice_name"`
	Gender    string   `json:"gender,omitempty"`
	Emotions  []string `json:"emotions,omitempty"` // æ”¯æŒçš„æƒ…æ„Ÿåˆ—è¡¨
}

// AIåŒ¹é…å“åº”
type VoiceMatchResponse struct {
	VoiceMatches map[string]int64 `json:"voice_matches"` // è§’è‰²å -> VoiceType (è…¾è®¯äº‘ä½¿ç”¨int64)
	Reasoning    string           `json:"reasoning,omitempty"`
}

// Config é…ç½®
type Config struct {
	SecretID  string
	SecretKey string
	Region    string
	LLMConfig LLMConfig
}

type LLMConfig struct {
	BaseURL string
	APIKey  string
	Model   string
}

// Process å¤„ç†æ•´ä¸ªéŸ³é¢‘ç”Ÿæˆæµç¨‹
func Process(scriptData ScriptData, outputDir string, cfg Config) error {
	fmt.Println("ðŸŽ¤ æ­¥éª¤å››: éŸ³é¢‘åˆæˆ (è…¾è®¯äº‘TTS)")
	fmt.Println("=====================================")
	fmt.Println()

	fmt.Printf("âœ… å·²åŠ è½½ %d ä¸ªåœºæ™¯ï¼Œ%d ä¸ªè§’è‰²\n\n", len(scriptData.Script), len(scriptData.Characters))

	// åˆ›å»ºè¾“å‡ºç›®å½•
	if err := os.MkdirAll(outputDir, 0o755); err != nil {
		return fmt.Errorf("åˆ›å»ºè¾“å‡ºç›®å½•å¤±è´¥: %v", err)
	}

	// èŽ·å–æ”¯æŒå¤šæƒ…æ„Ÿçš„éŸ³è‰²åˆ—è¡¨
	voices := getMultiEmotionVoices()
	fmt.Printf("âœ… å…±æœ‰ %d ç§å¤šæƒ…æ„ŸéŸ³è‰²å¯ç”¨\n\n", len(voices))

	// ä¸ºè§’è‰²ï¼ˆåŒ…æ‹¬æ—ç™½ï¼‰åŒ¹é…éŸ³è‰²
	fmt.Println("ðŸ¤– ä¸ºè§’è‰²å’Œæ—ç™½åŒ¹é…éŸ³è‰²...")
	voiceMatches, err := matchVoicesForCharacters(scriptData, voices, cfg.LLMConfig)
	if err != nil {
		fmt.Printf("âš ï¸  AIåŒ¹é…å¤±è´¥: %vï¼Œä½¿ç”¨è§„åˆ™åŒ¹é…\n", err)
		voiceMatches = simpleVoiceMatch(scriptData.Characters)
	}

	fmt.Println("âœ… éŸ³è‰²åŒ¹é…å®Œæˆ:")
	for char, voiceType := range voiceMatches {
		voiceName := "æœªçŸ¥éŸ³è‰²"
		for _, v := range voices {
			voiceID := parseVoiceType(v.VoiceType)
			if voiceID == voiceType {
				voiceName = v.VoiceName
				break
			}
		}
		fmt.Printf("  - %s: %s (VoiceType=%d)\n", char, voiceName, voiceType)
	}
	fmt.Println()

	// ä¿å­˜éŸ³è‰²åŒ¹é…ä¿¡æ¯
	matchesJSON, _ := json.MarshalIndent(voiceMatches, "", "  ")
	matchesFile := filepath.Join(outputDir, "voice_matches.json")
	if err := os.WriteFile(matchesFile, matchesJSON, 0o644); err != nil {
		fmt.Printf("âš ï¸  ä¿å­˜éŸ³è‰²åŒ¹é…ä¿¡æ¯å¤±è´¥: %v\n", err)
	}

	// ç»Ÿè®¡æ€»å¯¹è¯æ•°å’Œæ—ç™½æ•°
	totalDialogues := 0
	totalNarrations := 0
	for _, scene := range scriptData.Script {
		totalDialogues += len(scene.Dialogue)
		if scene.NarrationVO != "" {
			totalNarrations++
		}
	}

	if totalDialogues == 0 && totalNarrations == 0 {
		fmt.Println("âš ï¸  æ²¡æœ‰æ‰¾åˆ°å¯¹è¯å’Œæ—ç™½ï¼Œæ— éœ€ç”ŸæˆéŸ³é¢‘")
		return nil
	}

	fmt.Printf("ðŸ“Š éœ€è¦ç”Ÿæˆ %d ä¸ªå¯¹è¯éŸ³é¢‘å’Œ %d ä¸ªæ—ç™½éŸ³é¢‘\n\n", totalDialogues, totalNarrations)

	// åˆ›å»ºè…¾è®¯äº‘TTSå®¢æˆ·ç«¯
	credential := common.NewCredential(cfg.SecretID, cfg.SecretKey)
	cpf := profile.NewClientProfile()
	client, err := tts.NewClient(credential, cfg.Region, cpf)
	if err != nil {
		return fmt.Errorf("åˆ›å»ºè…¾è®¯äº‘TTSå®¢æˆ·ç«¯å¤±è´¥: %v", err)
	}

	// ç”Ÿæˆè¯­éŸ³æ–‡ä»¶
	fmt.Printf("ðŸŽ™ï¸  ç”Ÿæˆè¯­éŸ³æ–‡ä»¶...\n")
	currentIdx := 0
	totalItems := totalDialogues + totalNarrations

	for _, scene := range scriptData.Script {
		// 1. å…ˆç”Ÿæˆæ—ç™½éŸ³é¢‘ï¼ˆå¦‚æžœæœ‰ï¼‰
		if scene.NarrationVO != "" {
			currentIdx++

			// èŽ·å–æ—ç™½éŸ³è‰²
			voiceType, ok := voiceMatches["æ—ç™½"]
			if !ok {
				// å¦‚æžœæ²¡æœ‰åŒ¹é…åˆ°æ—ç™½éŸ³è‰²ï¼Œä½¿ç”¨é»˜è®¤éŸ³è‰²
				voiceType = 601001 // çˆ±å°æ´›ï¼Œé˜…è¯»å¥³å£°
			}

			// æ˜¾ç¤ºè¿›åº¦
			narrationPreview := scene.NarrationVO
			if len(narrationPreview) > 40 {
				narrationPreview = narrationPreview[:40] + "..."
			}
			fmt.Printf("[%d/%d] åœºæ™¯%d - æ—ç™½: %s\n",
				currentIdx, totalItems, scene.SceneID, narrationPreview)

			// ç”ŸæˆéŸ³é¢‘
			audioData, err := generateAudio(client, scene.NarrationVO, voiceType, "")
			if err != nil {
				fmt.Printf("  âŒ ç”Ÿæˆå¤±è´¥: %v\n", err)
			} else {
				// ä¿å­˜æ–‡ä»¶
				filename := fmt.Sprintf("scene_%03d_narration.mp3", scene.SceneID)
				filepath := filepath.Join(outputDir, filename)
				if err := os.WriteFile(filepath, audioData, 0o644); err != nil {
					fmt.Printf("  âŒ ä¿å­˜å¤±è´¥: %v\n", err)
				} else {
					fmt.Printf("  âœ… å·²ä¿å­˜: %s (%.1f KB)\n", filename, float64(len(audioData))/1024)
				}
			}
		}

		// 2. å†ç”Ÿæˆå¯¹è¯éŸ³é¢‘
		for dialogueIdx, dialogue := range scene.Dialogue {
			currentIdx++

			// èŽ·å–è§’è‰²å¯¹åº”çš„éŸ³è‰²
			voiceType, ok := voiceMatches[dialogue.Character]
			if !ok {
				voiceType = 601000 // ä½¿ç”¨é»˜è®¤éŸ³è‰²ï¼ˆçˆ±å°æºªï¼ŒèŠå¤©å¥³å£°ï¼‰
			}

			// æ˜¾ç¤ºè¿›åº¦
			linePreview := dialogue.Line
			if len(linePreview) > 30 {
				linePreview = linePreview[:30] + "..."
			}
			emotionInfo := ""
			if dialogue.Emotion != "" {
				emotionInfo = fmt.Sprintf(" [%s]", dialogue.Emotion)
			}
			fmt.Printf("[%d/%d] åœºæ™¯%d - %s%s: %s\n",
				currentIdx, totalItems, scene.SceneID, dialogue.Character, emotionInfo, linePreview)

			// ç”ŸæˆéŸ³é¢‘
			audioData, err := generateAudio(client, dialogue.Line, voiceType, dialogue.Emotion)
			if err != nil {
				fmt.Printf("  âŒ ç”Ÿæˆå¤±è´¥: %v\n", err)
				continue
			}

			// ä¿å­˜æ–‡ä»¶
			filename := fmt.Sprintf("scene_%03d_dialogue_%03d.mp3", scene.SceneID, dialogueIdx+1)
			filepath := filepath.Join(outputDir, filename)
			if err := os.WriteFile(filepath, audioData, 0o644); err != nil {
				fmt.Printf("  âŒ ä¿å­˜å¤±è´¥: %v\n", err)
				continue
			}

			fmt.Printf("  âœ… å·²ä¿å­˜: %s (%.1f KB)\n", filename, float64(len(audioData))/1024)
		}
	}

	fmt.Println()
	fmt.Printf("ðŸŽ‰ å®Œæˆï¼æ‰€æœ‰éŸ³é¢‘æ–‡ä»¶å·²ä¿å­˜åˆ°: %s\n", outputDir)
	fmt.Printf("   éŸ³è‰²åŒ¹é…ä¿¡æ¯: %s\n", matchesFile)

	return nil
}

// getMultiEmotionVoices è¿”å›žæ”¯æŒå¤šæƒ…æ„Ÿçš„è…¾è®¯äº‘éŸ³è‰²åˆ—è¡¨
// æ ¹æ®è…¾è®¯äº‘æ–‡æ¡£ï¼šhttps://cloud.tencent.com/document/product/1073/92668
// åªé€‰æ‹©"éŸ³è‰²æƒ…æ„Ÿ"åˆ—ä¸­æ”¯æŒå¤šç§æƒ…æ„Ÿçš„å¤§æ¨¡åž‹éŸ³è‰²
func getMultiEmotionVoices() []VoiceInfo {
	// è…¾è®¯äº‘å¤§æ¨¡åž‹éŸ³è‰² - æ”¯æŒå¤šæƒ…æ„Ÿ
	return []VoiceInfo{
		// å¤§æ¨¡åž‹éŸ³è‰² - å¥³å£°
		{
			VoiceType: "601000",
			VoiceName: "çˆ±å°æºªï¼ŒèŠå¤©å¥³å£°",
			Gender:    "female",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},
		{
			VoiceType: "601001",
			VoiceName: "çˆ±å°æ´›ï¼Œé˜…è¯»å¥³å£°",
			Gender:    "female",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},
		{
			VoiceType: "601003",
			VoiceName: "çˆ±å°è·ï¼Œé˜…è¯»å¥³å£°",
			Gender:    "female",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "news", "story", "radio", "poetry", "call"},
		},
		{
			VoiceType: "601005",
			VoiceName: "çˆ±å°é™ï¼ŒèŠå¤©å¥³å£°",
			Gender:    "female",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},
		{
			VoiceType: "601007",
			VoiceName: "çˆ±å°å¶ï¼ŒèŠå¤©å¥³å£°",
			Gender:    "female",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},
		{
			VoiceType: "601009",
			VoiceName: "çˆ±å°èŠŠï¼ŒèŠå¤©å¥³å£°",
			Gender:    "female",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},
		{
			VoiceType: "601010",
			VoiceName: "çˆ±å°å¨‡ï¼ŒèŠå¤©å¥³å£°",
			Gender:    "female",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},

		// å¤§æ¨¡åž‹éŸ³è‰² - ç”·å£°
		{
			VoiceType: "601002",
			VoiceName: "çˆ±å°è¾°ï¼ŒèŠå¤©ç”·å£°",
			Gender:    "male",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},
		{
			VoiceType: "601004",
			VoiceName: "çˆ±å°æ ‘ï¼Œèµ„è®¯ç”·å£°",
			Gender:    "male",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},
		{
			VoiceType: "601006",
			VoiceName: "çˆ±å°è€€ï¼Œé˜…è¯»ç”·å£°",
			Gender:    "male",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},
		{
			VoiceType: "601008",
			VoiceName: "çˆ±å°è±ªï¼ŒèŠå¤©ç”·å£°",
			Gender:    "male",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},

		// å¤§æ¨¡åž‹éŸ³è‰² - ç«¥å£°
		{
			VoiceType: "601015",
			VoiceName: "çˆ±å°ç«¥ï¼Œç”·ç«¥å£°",
			Gender:    "child",
			Emotions:  []string{"neutral", "sad", "happy", "angry", "fear", "sajiao", "amaze", "disgusted", "peaceful"},
		},

		// ç²¾å“éŸ³è‰² - å¥³ç«¥å£°ï¼ˆä»…ä¸­æ€§ï¼‰
		{
			VoiceType: "101016",
			VoiceName: "æ™ºç”œï¼Œå¥³ç«¥å£°",
			Gender:    "child",
			Emotions:  []string{"neutral"},
		},
	}
}

// matchVoicesForCharacters ä½¿ç”¨AIä¸ºè§’è‰²åŒ¹é…éŸ³è‰²
func matchVoicesForCharacters(scriptData ScriptData, voices []VoiceInfo, llmCfg LLMConfig) (map[string]int64, error) {
	config := openai.DefaultConfig(llmCfg.APIKey)
	config.BaseURL = llmCfg.BaseURL
	config.HTTPClient = &http.Client{
		Transport: &http.Transport{
			TLSClientConfig: &tls.Config{InsecureSkipVerify: true},
		},
	}

	client := openai.NewClientWithConfig(config)

	prompt := buildVoiceMatchPrompt(scriptData, voices)

	resp, err := client.CreateChatCompletion(
		context.Background(),
		openai.ChatCompletionRequest{
			Model: llmCfg.Model,
			Messages: []openai.ChatCompletionMessage{
				{
					Role:    openai.ChatMessageRoleSystem,
					Content: "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é…éŸ³å¯¼æ¼”ï¼Œæ“…é•¿æ ¹æ®è§’è‰²ç‰¹å¾é€‰æ‹©æœ€åˆé€‚çš„å£°éŸ³ã€‚",
				},
				{
					Role:    openai.ChatMessageRoleUser,
					Content: prompt,
				},
			},
			Temperature: 0.3,
		},
	)
	if err != nil {
		return nil, err
	}

	if len(resp.Choices) == 0 {
		return nil, fmt.Errorf("LLMè¿”å›žç©ºå“åº”")
	}

	content := resp.Choices[0].Message.Content

	// å°è¯•æå–JSON
	content = extractJSON(content)

	var matchResp VoiceMatchResponse
	if err := json.Unmarshal([]byte(content), &matchResp); err != nil {
		return nil, fmt.Errorf("è§£æžAIå“åº”å¤±è´¥: %v", err)
	}

	return matchResp.VoiceMatches, nil
}

// buildVoiceMatchPrompt æž„å»ºéŸ³è‰²åŒ¹é…æç¤ºè¯
func buildVoiceMatchPrompt(scriptData ScriptData, voices []VoiceInfo) string {
	var sb strings.Builder

	sb.WriteString("è¯·æ ¹æ®è§’è‰²æè¿°ã€æ—ç™½å†…å®¹å’Œå¯¹è¯æ ·æœ¬ï¼Œä¸ºæ¯ä¸ªè§’è‰²å’Œæ—ç™½é€‰æ‹©æœ€åˆé€‚çš„éŸ³è‰²ã€‚\n\n")

	// è§’è‰²åˆ—è¡¨ï¼ˆåŒ…æ‹¬æ—ç™½ï¼‰
	sb.WriteString("## è§’è‰²åˆ—è¡¨\n\n")

	// æ·»åŠ æ—ç™½è§’è‰²
	sb.WriteString("**æ—ç™½**: æ•…äº‹çš„å™è¿°è€…ï¼Œè´Ÿè´£è®²è¿°åœºæ™¯å’Œæ°›å›´\n\n")

	// å…¶ä»–è§’è‰²
	for char, desc := range scriptData.Characters {
		sb.WriteString(fmt.Sprintf("**%s**: %s\n\n", char, desc))
	}

	// åœºæ™¯å’Œå¯¹è¯æ ·æœ¬ï¼ˆå‰3ä¸ªåœºæ™¯ï¼‰
	sb.WriteString("## åœºæ™¯å’Œå¯¹è¯æ ·æœ¬\n\n")
	sampleCount := 0
	for _, scene := range scriptData.Script {
		if sampleCount >= 3 {
			break
		}
		sampleCount++
		sb.WriteString(fmt.Sprintf("åœºæ™¯%d (%s):\n", scene.SceneID, scene.Location))

		// æ˜¾ç¤ºæ—ç™½ï¼ˆç”»å¤–éŸ³ï¼‰
		if scene.NarrationVO != "" {
			sb.WriteString(fmt.Sprintf("- [æ—ç™½]: \"%s\"\n", truncateText(scene.NarrationVO, 60)))
		}

		// æ˜¾ç¤ºå¯¹è¯
		for _, dialogue := range scene.Dialogue {
			emotion := ""
			if dialogue.Emotion != "" {
				emotion = fmt.Sprintf(" [%s]", dialogue.Emotion)
			}
			sb.WriteString(fmt.Sprintf("- %s%s: \"%s\"\n", dialogue.Character, emotion, truncateText(dialogue.Line, 50)))
		}
		sb.WriteString("\n")
	}

	// å¯ç”¨éŸ³è‰²åˆ—è¡¨
	sb.WriteString("## å¯ç”¨éŸ³è‰²åˆ—è¡¨\n\n")
	sb.WriteString("| VoiceType | æ€§åˆ« | åç§° | æ”¯æŒçš„æƒ…æ„Ÿ |\n")
	sb.WriteString("|-----------|------|------|------------|\n")
	for _, v := range voices {
		emotionsStr := strings.Join(v.Emotions, ", ")
		sb.WriteString(fmt.Sprintf("| %s | %s | %s | %s |\n",
			v.VoiceType, v.Gender, v.VoiceName, emotionsStr))
	}

	sb.WriteString("\n## é€‰æ‹©æ ‡å‡†\n\n")
	sb.WriteString("1. **æ—ç™½**ï¼šä¼˜å…ˆé€‰æ‹©é˜…è¯»ç±»å£°éŸ³ï¼Œå¦‚\"çˆ±å°æ´›ï¼Œé˜…è¯»å¥³å£°\"(601001)æˆ–\"çˆ±å°è·ï¼Œé˜…è¯»å¥³å£°\"(601003)\n")
	sb.WriteString("2. æ ¹æ®è§’è‰²çš„å¹´é¾„ã€æ€§åˆ«ã€æ€§æ ¼é€‰æ‹©éŸ³è‰²\n")
	sb.WriteString("3. å„¿ç«¥è§’è‰²ä¼˜å…ˆé€‰æ‹©childç±»åˆ«çš„éŸ³è‰²ï¼ˆçˆ±å°ç«¥601015ã€æ™ºç”œ101016ï¼‰\n")
	sb.WriteString("4. èŠå¤©ç±»å¯¹è¯ä¼˜å…ˆé€‰æ‹©èŠå¤©å¥³å£°/ç”·å£°ï¼ˆå¦‚çˆ±å°æºª601000ã€çˆ±å°è¾°601002ï¼‰\n")
	sb.WriteString("5. è€ƒè™‘è§’è‰²çš„æƒ…æ„Ÿè¡¨è¾¾éœ€æ±‚ï¼Œå¤§æ¨¡åž‹éŸ³è‰²(601xxx)æ”¯æŒæ›´ä¸°å¯Œçš„æƒ…æ„Ÿ\n")
	sb.WriteString("6. ç¡®ä¿æ¯ä¸ªè§’è‰²ä½¿ç”¨ä¸åŒçš„éŸ³è‰²ï¼ˆå¦‚æžœå¯èƒ½ï¼‰\n\n")

	sb.WriteString("## è¾“å‡ºæ ¼å¼\n\n")
	sb.WriteString("ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼Œ**å¿…é¡»åŒ…å«\"æ—ç™½\"ä½œä¸ºkey**ï¼ŒVoiceTypeå¿…é¡»æ˜¯æ•´æ•°ï¼š\n")
	sb.WriteString("```json\n")
	sb.WriteString("{\n")
	sb.WriteString("  \"voice_matches\": {\n")
	sb.WriteString("    \"æ—ç™½\": 601001,\n")
	sb.WriteString("    \"è§’è‰²å1\": 601000,\n")
	sb.WriteString("    \"è§’è‰²å2\": 601002\n")
	sb.WriteString("  },\n")
	sb.WriteString("  \"reasoning\": \"é€‰æ‹©ç†ç”±çš„ç®€çŸ­è¯´æ˜Ž\"\n")
	sb.WriteString("}\n")
	sb.WriteString("```\n")
	sb.WriteString("\næ³¨æ„ï¼švoice_matches ä¸­çš„å€¼å¿…é¡»æ˜¯æ•´æ•°ç±»åž‹çš„VoiceTypeï¼Œå¿…é¡»åŒ…å«\"æ—ç™½\"ä½œä¸ºç¬¬ä¸€ä¸ªé”®å€¼å¯¹ã€‚\n")

	return sb.String()
}

// simpleVoiceMatch ç®€å•è§„åˆ™åŒ¹é…
func simpleVoiceMatch(characters map[string]string) map[string]int64 {
	matches := make(map[string]int64)
	usedVoices := make(map[int64]bool)

	// é¦–å…ˆä¸ºæ—ç™½é€‰æ‹©éŸ³è‰²
	matches["æ—ç™½"] = 601001 // çˆ±å°æ´›ï¼Œé˜…è¯»å¥³å£° - é€‚åˆæ—ç™½
	usedVoices[601001] = true

	for char, desc := range characters {
		descLower := strings.ToLower(desc)

		var voiceType int64

		// å„¿ç«¥
		if strings.Contains(descLower, "å°å¥³å­©") || strings.Contains(descLower, "å¥³ç«¥") ||
			(strings.Contains(descLower, "å¥³") && (strings.Contains(descLower, "å²") || strings.Contains(descLower, "å„¿ç«¥"))) {
			voiceType = 101016 // æ™ºç”œï¼Œå¥³ç«¥å£°
		} else if strings.Contains(descLower, "å°‘å¹´") || strings.Contains(descLower, "ç”·å­©") || strings.Contains(descLower, "ç”·ç«¥") {
			voiceType = 601015 // çˆ±å°ç«¥ï¼Œç”·ç«¥å£°
		} else if strings.Contains(descLower, "å¥³") || strings.Contains(descLower, "female") {
			voiceType = 601000 // çˆ±å°æºªï¼ŒèŠå¤©å¥³å£°
		} else {
			voiceType = 601002 // çˆ±å°è¾°ï¼ŒèŠå¤©ç”·å£°
		}

		// å¦‚æžœéŸ³è‰²å·²è¢«ä½¿ç”¨ï¼Œé€‰æ‹©å¤‡é€‰
		if usedVoices[voiceType] {
			voiceType = findAlternativeVoice(voiceType, usedVoices)
		}

		matches[char] = voiceType
		usedVoices[voiceType] = true
	}

	return matches
}

// findAlternativeVoice æ‰¾åˆ°å¤‡é€‰éŸ³è‰²
func findAlternativeVoice(originalVoice int64, usedVoices map[int64]bool) int64 {
	// æ ¹æ®åŽŸéŸ³è‰²çš„ç±»åž‹é€‰æ‹©å¤‡é€‰
	alternatives := map[int64][]int64{
		101016: {601000, 601005, 601007}, // å¥³ç«¥ -> å…¶ä»–å¥³å£°
		601015: {601002, 601008, 601004}, // ç”·ç«¥ -> å…¶ä»–ç”·å£°
		601000: {601005, 601007, 601009}, // èŠå¤©å¥³å£° -> å…¶ä»–å¥³å£°
		601002: {601008, 601004, 601006}, // èŠå¤©ç”·å£° -> å…¶ä»–ç”·å£°
		601001: {601003, 601000, 601005}, // é˜…è¯»å¥³å£° -> å…¶ä»–å¥³å£°
		601006: {601002, 601004, 601008}, // é˜…è¯»ç”·å£° -> å…¶ä»–ç”·å£°
	}

	if alts, ok := alternatives[originalVoice]; ok {
		for _, alt := range alts {
			if !usedVoices[alt] {
				return alt
			}
		}
	}

	// å¦‚æžœæ²¡æœ‰æ‰¾åˆ°ï¼Œè¿”å›žåŽŸéŸ³è‰²
	return originalVoice
}

// generateAudio ç”ŸæˆéŸ³é¢‘
func generateAudio(client *tts.Client, text string, voiceType int64, emotion string) ([]byte, error) {
	request := tts.NewTextToVoiceRequest()

	// ç”ŸæˆUUIDä½œä¸ºSessionId
	sessionID := uuid.New().String()

	request.Text = common.StringPtr(text)
	request.SessionId = common.StringPtr(sessionID)
	request.VoiceType = common.Int64Ptr(voiceType)
	request.Codec = common.StringPtr("mp3")
	request.SampleRate = common.Uint64Ptr(16000)

	// å¦‚æžœæŒ‡å®šäº†æƒ…æ„Ÿï¼Œåˆ™è®¾ç½®EmotionCategory
	if emotion != "" {
		request.EmotionCategory = common.StringPtr(emotion)
	}

	// è°ƒç”¨è…¾è®¯äº‘API
	response, err := client.TextToVoice(request)
	if err != nil {
		return nil, fmt.Errorf("è°ƒç”¨è…¾è®¯äº‘TTS APIå¤±è´¥: %v", err)
	}

	// è…¾è®¯äº‘è¿”å›žçš„éŸ³é¢‘æ•°æ®æ˜¯Base64ç¼–ç çš„
	if response.Response.Audio == nil {
		return nil, fmt.Errorf("APIè¿”å›žçš„éŸ³é¢‘æ•°æ®ä¸ºç©º")
	}

	audioData, err := base64.StdEncoding.DecodeString(*response.Response.Audio)
	if err != nil {
		return nil, fmt.Errorf("è§£ç éŸ³é¢‘æ•°æ®å¤±è´¥: %v", err)
	}

	return audioData, nil
}

// parseVoiceType å°†å­—ç¬¦ä¸²VoiceTypeè½¬æ¢ä¸ºint64
func parseVoiceType(voiceType string) int64 {
	var result int64
	fmt.Sscanf(voiceType, "%d", &result)
	return result
}

// extractJSON æå–JSONå†…å®¹
func extractJSON(content string) string {
	content = strings.TrimSpace(content)

	// ç§»é™¤markdownä»£ç å—æ ‡è®°
	content = strings.TrimPrefix(content, "```json")
	content = strings.TrimPrefix(content, "```")
	content = strings.TrimSuffix(content, "```")

	content = strings.TrimSpace(content)

	// å°è¯•æå–JSONå¯¹è±¡
	start := strings.Index(content, "{")
	end := strings.LastIndex(content, "}")
	if start != -1 && end != -1 && end > start {
		content = content[start : end+1]
	}

	return content
}

// truncateText æˆªæ–­æ–‡æœ¬
func truncateText(text string, maxLen int) string {
	if len(text) <= maxLen {
		return text
	}
	return text[:maxLen] + "..."
}
